{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Lightning Faces GAN\n",
    "This notebook trains the same face GAN in the other notebook, except it is built using the Pytorch Lightning framework. This allows for easy training with `.train()`, similar to Tensorflow.\n",
    "\n",
    "Following the documentation/tutorial on the [Lightning docs](https://pytorch-lightning.readthedocs.io/en/stable/notebooks/lightning_examples/basic-gan.html), we'll define our generator and discriminator as separate modules, like the previous module, and adjust the `training_step()` method in the `LightningModule` to define how to backpropagate the losses in both models."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import Packages\n",
    "The same packages as last time, with Pytorch Lightning."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed: 1729\n"
     ]
    },
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x23f092b6df0>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningDataModule, LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "seed = 1729\n",
    "print('Random Seed:', seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Configuration\n",
    "Same configuration as last time, set all the variables we plan to use, including the location of the data path."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Root directory for dataset\n",
    "dataroot = \"./Data/celeba\"\n",
    "# Number of workers for dataloader\n",
    "workers = 2\n",
    "# Batch size during training\n",
    "batch_size = 128\n",
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "image_size = 64\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 3\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 100\n",
    "# Size of feature maps in generator\n",
    "ngf = 64\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 64\n",
    "# Number of training epochs\n",
    "num_epochs = 5\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0.5\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 1\n",
    "\n",
    "device = torch.device('cuda:0' if (torch.cuda.is_available() and ngpu > 0) else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Lightning Data Module\n",
    "Instead of a raw `DataLoader` like before, we'll use PyTorch Lightning's own `DataLoader`. For a GAN, we don't need validation or test datasets."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class FacesDataModule(LightningDataModule):\n",
    "    def __init__(self, data_root, image_size, batch_size, num_workers):\n",
    "        super().__init__()\n",
    "        self.faces_train = None\n",
    "        self.data_root = data_root\n",
    "        self.image_size = image_size\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.CenterCrop(image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "\n",
    "    def prepare_data(self) -> None:\n",
    "        self.faces_train = dset.ImageFolder(root=self.data_root,\n",
    "                                            transform=self.transforms)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.faces_train, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generator and Disrciminator Modules\n",
    "For defining each neural network, we will use two separate modules. These will be directly `nn.Module`, so these themselves do not have anything to do with PyTorch Lightning.\n",
    "### Generator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz, ngf, nc, ngpu):\n",
    "        super().__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.model = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Discriminator\n",
    "Same thing for the discriminator. A simple init and forward methods."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, nc, ndf, ngpu):\n",
    "        super().__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.model = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initialization Method\n",
    "A quick method to initialize the two nets. This will be used in the entire module."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GAN creation\n",
    "Here is where we actually create the entire GAN, with both the generator and discriminator in the initialization."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "class GAN(LightningModule):\n",
    "    def __init__(self, lr, beta1, beta2=0.999, **kwargs):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        # Create the generator and discriminator and\n",
    "        # initialize the layers\n",
    "        self.generator = Generator(nz, ngf, nc, ngpu).to(device)\n",
    "        self.generator.apply(weights_init)\n",
    "        self.discriminator = Discriminator(nc, ndf, ngpu).to(device)\n",
    "        self.discriminator.apply(weights_init)\n",
    "\n",
    "        self.real_label = 1.\n",
    "        self.fake_label = 0.\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.generator(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        lr = self.hparams.lr\n",
    "        beta1 = self.hparams.beta1\n",
    "        beta2 = self.hparams.beta2\n",
    "\n",
    "        optimizerG = optim.Adam(self.generator.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "        optimizerD = optim.Adam(self.discriminator.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "        return [optimizerG, optimizerD], []\n",
    "\n",
    "    def adversarial_loss(self, y_hat, y):\n",
    "        return F.binary_cross_entropy(y_hat, y)\n",
    "\n",
    "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
    "        imgs, _ = batch\n",
    "        b_size = imgs.size(0)\n",
    "        # sample noise\n",
    "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "\n",
    "        # Train generator, maximize log(D(G(z)))\n",
    "        if optimizer_idx == 0:\n",
    "            # Generate \"real\" image batch with G\n",
    "            # label.fill_(self.fake_label)\n",
    "            # For purposes of generator, the target needs to be real,\n",
    "            # because the generator is trying to trick the discriminator.\n",
    "            label = torch.full((b_size,), self.real_label, dtype=torch.float).to(device)\n",
    "            # We call the discriminator on the generated output\n",
    "            output = self.discriminator(self(noise)).view(-1)\n",
    "            # Calculate loss and return\n",
    "            g_loss = self.adversarial_loss(output, label)\n",
    "            self.log('G_loss', g_loss, prog_bar=True)\n",
    "            return g_loss\n",
    "\n",
    "        # Train discriminator: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        if optimizer_idx == 1:\n",
    "            # label.fill_(self.real_label)\n",
    "            label = torch.full((b_size,), self.real_label, dtype=torch.float).to(device)\n",
    "            # Calculate loss for real images\n",
    "            real_loss = self.adversarial_loss(self.discriminator(imgs).view(-1), label)\n",
    "\n",
    "            # Now run fake images through = images that are generated\n",
    "            label = torch.full((b_size,), self.fake_label, dtype=torch.float).to(device)\n",
    "            fake_loss = self.adversarial_loss(self.discriminator(self(noise).detach()).view(-1), label)\n",
    "\n",
    "            # Discriminator loss is the average of these\n",
    "            d_loss = (real_loss + fake_loss) / 2\n",
    "            self.log('D_loss', d_loss, prog_bar=True)\n",
    "            return d_loss\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "dm = FacesDataModule(dataroot, image_size, batch_size, workers)\n",
    "model = GAN(lr, beta1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | generator     | Generator     | 3.6 M \n",
      "1 | discriminator | Discriminator | 2.8 M \n",
      "------------------------------------------------\n",
      "6.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.3 M     Total params\n",
      "25.369    Total estimated model params size (MB)\n",
      "C:\\Users\\mughi\\miniconda3\\envs\\pytorch_suite\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "35d57c9b78b24f66ac3e7f673f13a153"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    accelerator='auto',\n",
    "    devices=1 if torch.cuda.is_available() else None,\n",
    "    max_epochs=5,\n",
    "    callbacks=[TQDMProgressBar(refresh_rate=20)]\n",
    ")\n",
    "trainer.fit(model, dm)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "model.to(device)\n",
    "fake_images = model(fixed_noise).detach().cpu()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x23f4b802e20>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(np.transpose(fake_images[0], (1, 2, 0)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}